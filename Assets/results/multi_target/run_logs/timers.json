{
    "name": "root",
    "gauges": {
        "AgentController.Policy.Entropy.mean": {
            "value": 1.2823253870010376,
            "min": 1.2775317430496216,
            "max": 1.4299036264419556,
            "count": 48
        },
        "AgentController.Policy.Entropy.sum": {
            "value": 38846.765625,
            "min": 37779.2421875,
            "max": 47622.44140625,
            "count": 48
        },
        "AgentController.Environment.EpisodeLength.mean": {
            "value": 42.36179450072359,
            "min": 41.075524475524475,
            "max": 509.2716049382716,
            "count": 48
        },
        "AgentController.Environment.EpisodeLength.sum": {
            "value": 29272.0,
            "min": 3531.0,
            "max": 42849.0,
            "count": 48
        },
        "AgentController.Step.mean": {
            "value": 1439989.0,
            "min": 29946.0,
            "max": 1439989.0,
            "count": 48
        },
        "AgentController.Step.sum": {
            "value": 1439989.0,
            "min": 29946.0,
            "max": 1439989.0,
            "count": 48
        },
        "AgentController.Policy.ExtrinsicValueEstimate.mean": {
            "value": 21.385120391845703,
            "min": -0.08238375931978226,
            "max": 21.746116638183594,
            "count": 48
        },
        "AgentController.Policy.ExtrinsicValueEstimate.sum": {
            "value": 14798.50390625,
            "min": -21.584545135498047,
            "max": 15483.234375,
            "count": 48
        },
        "AgentController.Policy.CuriosityValueEstimate.mean": {
            "value": 0.40431636571884155,
            "min": 0.0011464930139482021,
            "max": 0.7615694999694824,
            "count": 48
        },
        "AgentController.Policy.CuriosityValueEstimate.sum": {
            "value": 279.78692626953125,
            "min": 0.3003811836242676,
            "max": 368.01141357421875,
            "count": 48
        },
        "AgentController.Environment.CumulativeReward.mean": {
            "value": 34.565846599131696,
            "min": -14.787234042553191,
            "max": 34.80854197349043,
            "count": 48
        },
        "AgentController.Environment.CumulativeReward.sum": {
            "value": 23885.0,
            "min": -695.0,
            "max": 24445.0,
            "count": 48
        },
        "AgentController.Policy.ExtrinsicReward.mean": {
            "value": 34.565846599131696,
            "min": -14.787234042553191,
            "max": 34.80854197349043,
            "count": 48
        },
        "AgentController.Policy.ExtrinsicReward.sum": {
            "value": 23885.0,
            "min": -695.0,
            "max": 24445.0,
            "count": 48
        },
        "AgentController.Policy.CuriosityReward.mean": {
            "value": 0.17508278769614813,
            "min": 0.16246103614251664,
            "max": 1.309549529023934,
            "count": 48
        },
        "AgentController.Policy.CuriosityReward.sum": {
            "value": 120.98220629803836,
            "min": 7.635668698698282,
            "max": 237.83158815838397,
            "count": 48
        },
        "AgentController.Losses.PolicyLoss.mean": {
            "value": 0.07209899772343911,
            "min": 0.06337792306178198,
            "max": 0.07211379990748104,
            "count": 48
        },
        "AgentController.Losses.PolicyLoss.sum": {
            "value": 1.0814849658515866,
            "min": 0.42408303597238106,
            "max": 1.0814849658515866,
            "count": 48
        },
        "AgentController.Losses.ValueLoss.mean": {
            "value": 10.588354223304323,
            "min": 1.304412708219864,
            "max": 11.528614219455491,
            "count": 48
        },
        "AgentController.Losses.ValueLoss.sum": {
            "value": 158.82531334956485,
            "min": 7.8264762493191835,
            "max": 171.91647720629092,
            "count": 48
        },
        "AgentController.Policy.LearningRate.mean": {
            "value": 0.0002572482902505747,
            "min": 0.0002572482902505747,
            "max": 0.00029945340018219997,
            "count": 48
        },
        "AgentController.Policy.LearningRate.sum": {
            "value": 0.00385872435375862,
            "min": 0.0017967204010931998,
            "max": 0.00441236243921253,
            "count": 48
        },
        "AgentController.Policy.Epsilon.mean": {
            "value": 0.18574942533333333,
            "min": 0.18574942533333333,
            "max": 0.19981780000000002,
            "count": 48
        },
        "AgentController.Policy.Epsilon.sum": {
            "value": 2.78624138,
            "min": 1.1989068,
            "max": 2.9707874699999994,
            "count": 48
        },
        "AgentController.Policy.Beta.mean": {
            "value": 0.008576367590799999,
            "min": 0.008576367590799999,
            "max": 0.009981798220000001,
            "count": 48
        },
        "AgentController.Policy.Beta.sum": {
            "value": 0.128645513862,
            "min": 0.059890789320000005,
            "max": 0.14708166825300004,
            "count": 48
        },
        "AgentController.Losses.CuriosityForwardLoss.mean": {
            "value": 0.1965766503786047,
            "min": 0.12340350205498866,
            "max": 0.38192027017828967,
            "count": 48
        },
        "AgentController.Losses.CuriosityForwardLoss.sum": {
            "value": 2.9486497556790705,
            "min": 1.3574385226048753,
            "max": 5.346883782496056,
            "count": 48
        },
        "AgentController.Losses.CuriosityInverseLoss.mean": {
            "value": 0.8384334592355621,
            "min": 0.7568440162798478,
            "max": 1.8225751108554598,
            "count": 48
        },
        "AgentController.Losses.CuriosityInverseLoss.sum": {
            "value": 12.576501888533432,
            "min": 10.595816227917869,
            "max": 22.761453919112682,
            "count": 48
        },
        "AgentController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 48
        },
        "AgentController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 48
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1717856640",
        "python_version": "3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\turga\\anaconda3\\envs\\VR_Experience\\Scripts\\mlagents-learn config/agentcontroller.yaml --run-id=multi_target --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1717858505"
    },
    "total": 1864.4062823,
    "count": 1,
    "self": 0.007006399999909263,
    "children": {
        "run_training.setup": {
            "total": 0.09169620000000012,
            "count": 1,
            "self": 0.09169620000000012
        },
        "TrainerController.start_learning": {
            "total": 1864.3075797000001,
            "count": 1,
            "self": 1.0012637999998333,
            "children": {
                "TrainerController._reset_env": {
                    "total": 20.7947212,
                    "count": 1,
                    "self": 20.7947212
                },
                "TrainerController.advance": {
                    "total": 1842.3914666000003,
                    "count": 33515,
                    "self": 0.797513300008859,
                    "children": {
                        "env_step": {
                            "total": 579.2264692999884,
                            "count": 33515,
                            "self": 516.5764089999823,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 62.14535869999529,
                                    "count": 33515,
                                    "self": 2.069447299988447,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 60.075911400006845,
                                            "count": 17854,
                                            "self": 60.075911400006845
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.5047016000108542,
                                    "count": 33514,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1781.79491130001,
                                            "count": 33514,
                                            "is_parallel": true,
                                            "self": 1403.7499324000296,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.001785300000001655,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0003221000000017682,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0014631999999998868,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0014631999999998868
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 378.04319359998044,
                                                    "count": 33514,
                                                    "is_parallel": true,
                                                    "self": 15.17331479999649,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 24.925945099991754,
                                                            "count": 33514,
                                                            "is_parallel": true,
                                                            "self": 24.925945099991754
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 306.5747954999872,
                                                            "count": 33514,
                                                            "is_parallel": true,
                                                            "self": 306.5747954999872
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 31.369138200005004,
                                                            "count": 33514,
                                                            "is_parallel": true,
                                                            "self": 7.836227400033366,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 23.53291079997164,
                                                                    "count": 134056,
                                                                    "is_parallel": true,
                                                                    "self": 23.53291079997164
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1262.367484000003,
                            "count": 33514,
                            "self": 2.674777099974108,
                            "children": {
                                "process_trajectory": {
                                    "total": 213.68265680002662,
                                    "count": 33514,
                                    "self": 213.45227280002678,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.2303839999998445,
                                            "count": 2,
                                            "self": 0.2303839999998445
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1046.0100501000022,
                                    "count": 679,
                                    "self": 620.2301555999918,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 425.77989450001036,
                                            "count": 33210,
                                            "self": 425.77989450001036
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.12012810000010177,
                    "count": 1,
                    "self": 0.02483200000006036,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.0952961000000414,
                            "count": 1,
                            "self": 0.0952961000000414
                        }
                    }
                }
            }
        }
    }
}